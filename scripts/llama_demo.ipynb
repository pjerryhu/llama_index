{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:32:27.581204Z",
     "start_time": "2023-09-15T05:32:27.574362Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../jerry.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2614ff7f608113f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:23:26.837385Z",
     "start_time": "2023-09-15T05:23:26.661771Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import os\n",
    "\n",
    "api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "pinecone.init(api_key=api_key, environment=\"us-west1-gcp-free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa9f5f12d31646b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:25:01.277212Z",
     "start_time": "2023-09-15T05:23:27.374796Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pinecone.create_index(\"quickstart\", dimension=1536, metric=\"euclidean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190ac68de9331761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:25:01.288103Z",
     "start_time": "2023-09-15T05:25:01.281291Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pinecone_index = pinecone.Index(\"quickstart\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "943b1f07e26a6789",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:25:23.827613Z",
     "start_time": "2023-09-15T05:25:19.152225Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c86efc9f4f4aecb5c4136ef04f56f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca984a11be424ccc940648534254947a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0225b2619b5e448d93b094ceb72e943a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0077dde74141259da3a52ef274cc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.vector_stores import PineconeVectorStore\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed0902e3d454c4a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:25:45.970352Z",
     "start_time": "2023-09-15T05:25:34.130403Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-14 22:25:34--  https://arxiv.org/pdf/2307.09288.pdf\r\n",
      "Resolving arxiv.org (arxiv.org)... 128.84.21.199\r\n",
      "Connecting to arxiv.org (arxiv.org)|128.84.21.199|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 13661300 (13M) [application/pdf]\r\n",
      "Saving to: ‘data/llama2.pdf’\r\n",
      "\r\n",
      "data/llama2.pdf     100%[===================>]  13.03M  1017KB/s    in 10s     \r\n",
      "\r\n",
      "2023-09-14 22:25:45 (1.24 MB/s) - ‘data/llama2.pdf’ saved [13661300/13661300]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27b85c0f2a41581b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:26:02.787853Z",
     "start_time": "2023-09-15T05:26:02.777550Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_hub.file.pymu_pdf.base import PyMuPDFReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7576becd5d2f73a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:27:04.686557Z",
     "start_time": "2023-09-15T05:27:03.946162Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loader = PyMuPDFReader()\n",
    "documents = loader.load(file_path=\"./data/llama2.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a86c2269e8d98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:27:35.123376Z",
     "start_time": "2023-09-15T05:27:34.839671Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.text_splitter import SentenceSplitter\n",
    "text_splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    # separator=\" \",\n",
    ")\n",
    "text_chunks = []\n",
    "# maintain relationship with source doc index, to help inject doc metadata in (3)\n",
    "doc_idxs = []\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    cur_text_chunks = text_splitter.split_text(doc.text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8be102580aeea87c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:28:47.986363Z",
     "start_time": "2023-09-15T05:28:47.981283Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.schema import TextNode\n",
    "nodes = []\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(\n",
    "        text=text_chunk,\n",
    "    )\n",
    "    src_doc = documents[doc_idxs[idx]]\n",
    "    node.metadata = src_doc.metadata\n",
    "    nodes.append(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71a3ab45df48fe46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:29:10.427381Z",
     "start_time": "2023-09-15T05:29:10.422798Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_pages: 77\n",
      "file_path: ./data/llama2.pdf\n",
      "source: 2\n",
      "\n",
      "Contents\n",
      "1\n",
      "Introduction\n",
      "3\n",
      "2\n",
      "Pretraining\n",
      "5\n",
      "2.1\n",
      "Pretraining Data .............................................5\n",
      "2.2\n",
      "Training Details .............................................5\n",
      "2.3\n",
      "Llama 2 Pretrained Model Evaluation ................................7\n",
      "3\n",
      "Fine-tuning\n",
      "8\n",
      "3.1\n",
      "Supervised Fine-Tuning (SFT) .....................................9\n",
      "3.2\n",
      "Reinforcement Learning with Human Feedback (RLHF)\n",
      ".....................9\n",
      "3.3\n",
      "System Message for Multi-Turn Consistency .............................16\n",
      "3.4\n",
      "RLHF Results\n",
      "..............................................17\n",
      "4\n",
      "Safety\n",
      "20\n",
      "4.1\n",
      "Safety in Pretraining\n",
      "..........................................20\n",
      "4.2\n",
      "Safety Fine-Tuning\n",
      "...........................................23\n",
      "4.3\n",
      "Red Teaming ...............................................28\n",
      "4.4\n",
      "Safety Evaluation of Llama 2-Chat ..................................29\n",
      "5\n",
      "Discussion\n",
      "32\n",
      "5.1\n",
      "Learnings and Observations ......................................32\n",
      "5.2\n",
      "Limitations and Ethical Considerations\n",
      "...............................34\n",
      "5.3\n",
      "Responsible Release Strategy\n",
      ".....................................35\n",
      "6\n",
      "Related Work\n",
      "35\n",
      "7\n",
      "Conclusion\n",
      "36\n",
      "A Appendix\n",
      "46\n",
      "A.1 Contributions ..............................................46\n",
      "A.2 Additional Details for Pretraining ...................................47\n",
      "A.3 Additional Details for Fine-tuning\n",
      "..................................51\n",
      "A.4 Additional Details for Safety ......................................58\n",
      "A.5 Data Annotation .............................................72\n",
      "A.6 Dataset Contamination ................\n"
     ]
    }
   ],
   "source": [
    "# print a sample node\n",
    "print(nodes[1].get_content(metadata_mode=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1aa6271c74414a10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:33:32.596558Z",
     "start_time": "2023-09-15T05:33:32.589402Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from llama_index.node_parser.extractors import (\n",
    "    MetadataExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    ")\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "metadata_extractor = MetadataExtractor(\n",
    "    extractors=[\n",
    "        TitleExtractor(nodes=5, llm=llm),\n",
    "        QuestionsAnsweredExtractor(questions=3, llm=llm),\n",
    "    ],\n",
    "    in_place=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfe1ae71b3b6ed1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:40:54.334065Z",
     "start_time": "2023-09-15T05:33:33.640536Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aef1992c57e4886a42105cd8e0f31e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting questions:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes = metadata_extractor.process_nodes(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a03d9077a440ccb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-15T05:50:04.717596Z",
     "start_time": "2023-09-15T05:50:04.709403Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextNode(id_='440dd934-e1d7-40ce-af68-4ba48fc741be', embedding=None, metadata={'total_pages': 77, 'file_path': './data/llama2.pdf', 'source': '1', 'document_title': 'Llama 2: Pretraining, Fine-tuning, Safety, and Discussion for Developing and Evaluating a Pretrained and Fine-Tuned Large Language Model, and Release of Llama 2 and Llama 2-Chat Models for Research and Commercial Use', 'questions_this_excerpt_can_answer': '1. What is the purpose of Llama 2 and what makes it different from other large language models?\\n2. How does Llama 2-Chat perform compared to open-source chat models in terms of benchmarks and human evaluations?\\n3. What are the details of the fine-tuning and safety improvements made to Llama 2-Chat, and how can the community contribute to the responsible development of large language models?'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=['questions_this_excerpt_can_answer'], relationships={}, hash='98ef71d6b4ce195ef3323de8aa571372161f2b9864cc7aad637b3d15081f6c3e', text='Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗\\nLouis Martin†\\nKevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\\nSergey Edunov\\nThomas Scialom∗\\nGenAI, Meta\\nAbstract\\nIn this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\\nlarge language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\\nOur fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our\\nmodels outperform open-source chat models on most benchmarks we tested, and based on\\nour human evaluations for helpfulness and safety, may be a suitable substitute for closed-\\nsource models. We provide a detailed description of our approach to fine-tuning and safety\\nimprovements of Llama 2-Chat in order to enable the community to build on our work and\\ncontribute to the responsible development of LLMs.\\n∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\\n†Second author\\nContributions for all the authors can be found in Section A.1.\\narXiv:2307.09288v2  [cs.CL]  19 Jul 2023', start_char_idx=None, end_char_idx=None, text_template='[Excerpt from document]\\n{metadata_str}\\nExcerpt:\\n-----\\n{content}\\n-----\\n', metadata_template='{key}: {value}', metadata_seperator='\\n')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa09f82e64b768",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
